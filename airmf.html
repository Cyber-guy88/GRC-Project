<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Risk Management Framework</title>
    <link rel="stylesheet" href="css/airmf.css">
    <link rel="icon" href="favicon.ico" type="image/x-icon">
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700;800&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css">
</head>
<body>
    <div class="hero-section">
        <div class="hero-content">
            <div class="badge">
                <i class="fas fa-robot"></i>
                AI Governance Framework
            </div>
            <h1>AI Risk Management Framework</h1>
            <p class="hero-subtitle">Comprehensive framework for managing AI-related risks and ensuring responsible AI deployment</p>
            <div class="hero-stats">
                <div class="stat-item">
                    <span class="stat-number">5</span>
                    <span class="stat-label">Core Pillars</span>
                </div>
                <div class="stat-item">
                    <span class="stat-number">20+</span>
                    <span class="stat-label">Risk Categories</span>
                </div>
                <div class="stat-item">
                    <span class="stat-number">100%</span>
                    <span class="stat-label">Compliance Focus</span>
                </div>
            </div>
        </div>
    </div>

    <nav class="page-nav">
        <div class="nav-container">
            <a href="#overview" class="nav-item active">Overview</a>
            <a href="#purpose" class="nav-item">Purpose & Scope</a>
            <a href="#components" class="nav-item">Core Components</a>
            <a href="#implementation" class="nav-item">Implementation</a>
            <a href="#features" class="nav-item">Key Features</a>
            <a href="#benefits" class="nav-item">Benefits</a>
            <a href="#comparison" class="nav-item">Comparison</a>
            <a href="#future" class="nav-item">Future Directions</a>
        </div>
    </nav>

    <main class="main-content">
        <section id="overview" class="content-section">
            <div class="section-header">
                <div class="icon-circle">
                    <i class="fas fa-info-circle"></i>
                </div>
                <h2>Framework Overview</h2>
            </div>
            <div class="content-card">
                <p>The NIST AI Risk Management Framework (AI RMF), released in January 2023, is a voluntary guidance tool designed to help organizations manage risks associated with artificial intelligence (AI) systems. Developed through collaboration with over 240 stakeholders from industry, academia, civil society, and government, it emphasizes building trustworthy AI by addressing technical, ethical, and governance challenges.</p>
            </div>
        </section>

        <section id="purpose" class="content-section">
            <div class="section-header">
                <div class="icon-circle">
                    <i class="fas fa-bullseye"></i>
                </div>
                <h2>Purpose and Scope</h2>
            </div>
            <div class="content-card">
                <h3>The AI RMF aims to:</h3>
                <ul>
                    <li>Mitigate risks (e.g., bias, privacy breaches, security vulnerabilities) across the AI lifecycle.</li>
                    <li>Promote trustworthiness in AI systems by aligning with principles like transparency, fairness, and accountability.</li>
                    <li>Support compliance with emerging regulations (e.g., EU AI Act, ISO 42001) and foster societal trust.</li>
                </ul>
                
                <h3>Applicability:</h3>
                <ul>
                    <li>Applies to all organizations designing, developing, deploying, or using AI systems, regardless of size or sector.</li>
                    <li>Includes generative AI systems, with a dedicated Generative AI Profile released in July 2024.</li>
                </ul>
            </div>
        </section>

        <section id="components" class="content-section">
            <div class="section-header">
                <div class="icon-circle">
                    <i class="fas fa-puzzle-piece"></i>
                </div>
                <h2>Core Components</h2>
            </div>
            <div class="content-card">
                <p>The framework is divided into two parts and structured around four core functions:</p>
                
                <h3>Part 1: Foundational Information</h3>
                <h4>Categories of Harm:</h4>
            <div class="info-grid">
                <div class="info-item">
                    <div class="item-header">
                            <i class="fas fa-user-shield"></i>
                            <h3>Harm to People</h3>
                        </div>
                        <p>Threats to civil liberties, safety, or economic opportunities.</p>
                    </div>
                    <div class="info-item">
                        <div class="item-header">
                            <i class="fas fa-building"></i>
                            <h3>Harm to Organizations</h3>
                        </div>
                        <p>Operational disruptions, financial loss, reputational damage.</p>
                </div>
                <div class="info-item">
                    <div class="item-header">
                            <i class="fas fa-globe"></i>
                            <h3>Harm to Ecosystems</h3>
                        </div>
                        <p>Environmental damage, global supply chain disruptions.</p>
                    </div>
                </div>
                
                <h4>Challenges:</h4>
                <ul>
                    <li>Risk measurement difficulties (e.g., undefined metrics, emergent risks).</li>
                    <li>Socio-technical complexities requiring multidisciplinary input.</li>
                </ul>
                
                <h3>Part 2: Core and Profiles</h3>
                <h4>Four Core Functions:</h4>
                <div class="info-grid">
                    <div class="info-item">
                        <div class="item-header">
                            <i class="fas fa-gavel"></i>
                            <h3>Govern</h3>
                        </div>
                        <p>Establish governance structures, policies, and accountability mechanisms. Focuses on leadership commitment, workforce diversity, and risk-aware culture.</p>
                    </div>
                    <div class="info-item">
                        <div class="item-header">
                            <i class="fas fa-map-marked-alt"></i>
                            <h3>Map</h3>
                        </div>
                        <p>Identify risks by engaging stakeholders and contextualizing AI systems within their operational environments.</p>
                    </div>
                    <div class="info-item">
                        <div class="item-header">
                            <i class="fas fa-chart-bar"></i>
                            <h3>Measure</h3>
                        </div>
                        <p>Assess risks using quantitative/qualitative tools (e.g., bias detection, adversarial testing).</p>
                </div>
                <div class="info-item">
                    <div class="item-header">
                            <i class="fas fa-tasks"></i>
                            <h3>Manage</h3>
                        </div>
                        <p>Allocate resources to mitigate risks, prioritize actions, and document residual risks.</p>
                    </div>
                </div>
                
                <h4>Trustworthy AI Characteristics:</h4>
                <ul>
                    <li>Valid/Reliable</li>
                    <li>Safe/Secure</li>
                    <li>Accountable/Transparent</li>
                    <li>Explainable</li>
                    <li>Privacy-Enhanced</li>
                    <li>Fair (bias managed)</li>
                </ul>
            </div>
        </section>

        <section id="implementation" class="content-section">
            <div class="section-header">
                <div class="icon-circle">
                    <i class="fas fa-tasks"></i>
                </div>
                <h2>Implementation Workflow</h2>
            </div>
            <div class="content-card">
                <p>Organizations can adopt the AI RMF through a five-step process:</p>
                
                <div class="implementation-timeline">
                    <div class="timeline-item">
                        <div class="timeline-content">
                            <h3>1. Define AI System Goals</h3>
                            <p>Clarify objectives and associated risks (e.g., credit scoring vs. autonomous vehicles).</p>
                        </div>
                    </div>
                    <div class="timeline-item">
                        <div class="timeline-content">
                            <h3>2. Assess Data Sources</h3>
                            <p>Identify biases in training data and mitigate ethical risks.</p>
                        </div>
                    </div>
                    <div class="timeline-item">
                        <div class="timeline-content">
                            <h3>3. Integrate RMF During Development</h3>
                            <p>Embed Govern, Map, Measure, and Manage functions into the AI lifecycle.</p>
                        </div>
                    </div>
                    <div class="timeline-item">
                        <div class="timeline-content">
                            <h3>4. Monitor and Test</h3>
                            <p>Continuously evaluate performance and trustworthiness post-deployment.</p>
                        </div>
                    </div>
                    <div class="timeline-item">
                        <div class="timeline-content">
                            <h3>5. Iterate and Improve</h3>
                            <p>Use feedback to refine systems and adapt to evolving risks.</p>
                        </div>
                    </div>
                </div>
            </div>
        </section>

        <section id="features" class="content-section">
            <div class="section-header">
                <div class="icon-circle">
                    <i class="fas fa-star"></i>
                </div>
                <h2>Key Features</h2>
            </div>
            <div class="info-grid">
                <div class="info-item">
                    <div class="item-header">
                        <i class="fas fa-users"></i>
                        <h3>Socio-Technical Approach</h3>
                    </div>
                    <p>Balances technical rigor with ethical, legal, and societal considerations.</p>
                </div>
                <div class="info-item">
                    <div class="item-header">
                        <i class="fas fa-sync-alt"></i>
                        <h3>Flexibility</h3>
                    </div>
                    <p>Adaptable to diverse sectors (e.g., healthcare, finance) and risk profiles.</p>
                </div>
                <div class="info-item">
                    <div class="item-header">
                        <i class="fas fa-file-alt"></i>
                        <h3>Documentation Emphasis</h3>
                    </div>
                    <p>Requires thorough recording of roles, system limits, and risk decisions.</p>
                </div>
                <div class="info-item">
                    <div class="item-header">
                        <i class="fas fa-link"></i>
                        <h3>Framework Alignment</h3>
                    </div>
                    <p>Complements NIST Cybersecurity Framework (CSF), ISO 27001, and OECD AI Principles.</p>
                </div>
            </div>
        </section>

        <section id="benefits" class="content-section">
            <div class="section-header">
                <div class="icon-circle">
                    <i class="fas fa-star"></i>
                </div>
                <h2>Benefits and Challenges</h2>
            </div>
            <div class="content-card">
                <h3>Benefits</h3>
            <div class="benefits-grid">
                <div class="benefit-item">
                    <div class="item-header">
                            <i class="fas fa-shield-alt"></i>
                            <h3>Proactive Risk Culture</h3>
                        </div>
                        <p>Shifts from reactive to anticipatory risk management.</p>
                    </div>
                    <div class="benefit-item">
                        <div class="item-header">
                            <i class="fas fa-file-contract"></i>
                            <h3>Regulatory Preparedness</h3>
                        </div>
                        <p>Aligns with global standards (e.g., GDPR, EU AI Act).</p>
                </div>
                <div class="benefit-item">
                    <div class="item-header">
                        <i class="fas fa-handshake"></i>
                        <h3>Stakeholder Trust</h3>
                    </div>
                        <p>Enhances transparency and accountability.</p>
                    </div>
                </div>
                
                <h3>Challenges</h3>
                <div class="benefits-grid">
                    <div class="benefit-item">
                        <div class="item-header">
                            <i class="fas fa-money-bill-wave"></i>
                            <h3>Resource Intensity</h3>
                        </div>
                        <p>Requires significant investment in training and tools, especially for SMEs.</p>
                    </div>
                    <div class="benefit-item">
                        <div class="item-header">
                            <i class="fas fa-file-signature"></i>
                            <h3>Voluntary Nature</h3>
                        </div>
                        <p>Lacks enforcement mechanisms, relying on organizational commitment.</p>
                </div>
                <div class="benefit-item">
                    <div class="item-header">
                            <i class="fas fa-sync"></i>
                            <h3>Evolving Practices</h3>
                        </div>
                        <p>Implementation strategies are still maturing.</p>
                    </div>
                </div>
            </div>
        </section>

        <section id="comparison" class="content-section">
            <div class="section-header">
                <div class="icon-circle">
                        <i class="fas fa-balance-scale"></i>
                </div>
                <h2>Comparison with Other Frameworks</h2>
            </div>
            <div class="content-card">
                <table class="comparison-table">
                    <thead>
                        <tr>
                            <th>Aspect</th>
                            <th>NIST AI RMF</th>
                            <th>NIST RMF (Traditional)</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>Focus</td>
                            <td>AI-specific risks (bias, transparency)</td>
                            <td>General cybersecurity/privacy risks</td>
                        </tr>
                        <tr>
                            <td>Scope</td>
                            <td>Socio-technical, ethical dimensions</td>
                            <td>Technical controls for IT systems</td>
                        </tr>
                        <tr>
                            <td>Audience</td>
                            <td>AI developers, policymakers</td>
                            <td>IT security teams</td>
                        </tr>
                        <tr>
                            <td>Key Tools</td>
                            <td>Generative AI Profile, Playbook</td>
                            <td>Continuous monitoring, control mapping</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </section>

        <section id="future" class="content-section">
            <div class="section-header">
                <div class="icon-circle">
                    <i class="fas fa-rocket"></i>
                </div>
                <h2>Future Directions</h2>
            </div>
            <div class="content-card">
                <div class="info-grid">
                    <div class="info-item">
                        <div class="item-header">
                            <i class="fas fa-brain"></i>
                            <h3>Generative AI Integration</h3>
                        </div>
                        <p>The 2024 Generative AI Profile addresses unique risks (e.g., misinformation, deepfakes).</p>
                    </div>
                    <div class="info-item">
                        <div class="item-header">
                            <i class="fas fa-globe-americas"></i>
                            <h3>Global Adoption</h3>
                        </div>
                        <p>Translations in Japanese and Arabic aim to foster international alignment.</p>
                    </div>
                    <div class="info-item">
                        <div class="item-header">
                            <i class="fas fa-sync-alt"></i>
                            <h3>Continuous Updates</h3>
                        </div>
                        <p>NIST's Trustworthy AI Resource Center supports evolving best practices.</p>
                    </div>
                </div>
                
                <div class="key-takeaway">
                    <h3>Key Takeaway</h3>
                    <p>The NIST AI RMF provides a robust, flexible roadmap for managing AI risks while fostering innovation. By prioritizing governance, stakeholder engagement, and iterative improvement, organizations can harness AI's potential responsibly. For implementation tools, refer to the AI RMF Playbook and Generative AI Profile.</p>
                </div>
            </div>
        </section>
    </main>

    <script>
        // Navigation highlighting
        document.addEventListener('DOMContentLoaded', function() {
            const sections = document.querySelectorAll('.content-section');
            const navItems = document.querySelectorAll('.nav-item');
            
            // Add visible class to sections for animation
            setTimeout(() => {
                sections.forEach(section => {
                    section.classList.add('visible');
                });
            }, 100);
            
            // Navigation scroll behavior
            navItems.forEach(item => {
            item.addEventListener('click', function(e) {
                e.preventDefault();
                    const targetId = this.getAttribute('href');
                    const targetSection = document.querySelector(targetId);
                    
                    window.scrollTo({
                        top: targetSection.offsetTop - 100,
                        behavior: 'smooth'
                    });
                    
                    navItems.forEach(nav => nav.classList.remove('active'));
                this.classList.add('active');
                });
            });
            
            // Scroll spy for navigation
            window.addEventListener('scroll', function() {
                let current = '';
                
                sections.forEach(section => {
                    const sectionTop = section.offsetTop;
                    const sectionHeight = section.clientHeight;
                    if(pageYOffset >= (sectionTop - 200)) {
                        current = section.getAttribute('id');
                    }
                });
                
                navItems.forEach(item => {
                    item.classList.remove('active');
                    if(item.getAttribute('href').slice(1) === current) {
                        item.classList.add('active');
                    }
                });
                
                // Add scrolled class to navigation for shadow
                const nav = document.querySelector('.page-nav');
                if(pageYOffset > 50) {
                    nav.classList.add('scrolled');
                } else {
                    nav.classList.remove('scrolled');
                }
            });
        });
    </script>
</body>
</html>


